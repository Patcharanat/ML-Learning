{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "4885953f",
   "metadata": {},
   "source": [
    "# For learning ML developing in a regression task\n",
    "*By: Patcharanat P.*\n",
    "\n",
    "Predict MaxTemp, MinTemp, and MeanTemp using other features as input.\n",
    "\n",
    "this notebook includes multiple aspect of developing model as following:\n",
    "- Filling missing value with a Mean or Median value\n",
    "- RandomForestRegressor\n",
    "- Multivariate feature imputation (IterativeImputer)\n",
    "- (MSE and MAE explaination)\n",
    "- a Baseline model & a Benchmark model\n",
    "- Normalization (MinMaxScaler, RobustScaler, StandardScaler exclude Normalizer)\n",
    "- Using time series cross validator (In progress...)\n",
    "\n",
    "read README.md for more detail"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "030fee3f",
   "metadata": {},
   "source": [
    "> Note that the dataset used in this project wasn't given definition of each column, so domain knowledge or feature engineering won't be apply in the project."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "89ac03e9",
   "metadata": {},
   "source": [
    "## Import Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 518,
   "id": "89f5e6e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns; sns.set_style('dark')\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from time import time\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "89be283a",
   "metadata": {},
   "source": [
    "## Data Pre-processing (Load Data & Data Cleaning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 519,
   "id": "4ca1747c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('Summary of Weather.csv', low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 520,
   "id": "bd4dcbb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 119040 entries, 0 to 119039\n",
      "Data columns (total 31 columns):\n",
      " #   Column       Non-Null Count   Dtype  \n",
      "---  ------       --------------   -----  \n",
      " 0   STA          119040 non-null  int64  \n",
      " 1   Date         119040 non-null  object \n",
      " 2   Precip       119040 non-null  object \n",
      " 3   WindGustSpd  532 non-null     float64\n",
      " 4   MaxTemp      119040 non-null  float64\n",
      " 5   MinTemp      119040 non-null  float64\n",
      " 6   MeanTemp     119040 non-null  float64\n",
      " 7   Snowfall     117877 non-null  object \n",
      " 8   PoorWeather  34237 non-null   object \n",
      " 9   YR           119040 non-null  int64  \n",
      " 10  MO           119040 non-null  int64  \n",
      " 11  DA           119040 non-null  int64  \n",
      " 12  PRCP         117108 non-null  object \n",
      " 13  DR           533 non-null     float64\n",
      " 14  SPD          532 non-null     float64\n",
      " 15  MAX          118566 non-null  float64\n",
      " 16  MIN          118572 non-null  float64\n",
      " 17  MEA          118542 non-null  float64\n",
      " 18  SNF          117877 non-null  object \n",
      " 19  SND          5563 non-null    float64\n",
      " 20  FT           0 non-null       float64\n",
      " 21  FB           0 non-null       float64\n",
      " 22  FTI          0 non-null       float64\n",
      " 23  ITH          0 non-null       float64\n",
      " 24  PGT          525 non-null     float64\n",
      " 25  TSHDSBRSGF   34237 non-null   object \n",
      " 26  SD3          0 non-null       float64\n",
      " 27  RHX          0 non-null       float64\n",
      " 28  RHN          0 non-null       float64\n",
      " 29  RVG          0 non-null       float64\n",
      " 30  WTE          0 non-null       float64\n",
      "dtypes: float64(20), int64(4), object(7)\n",
      "memory usage: 28.2+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 521,
   "id": "a0785375",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>STA</th>\n",
       "      <th>Date</th>\n",
       "      <th>Precip</th>\n",
       "      <th>WindGustSpd</th>\n",
       "      <th>MaxTemp</th>\n",
       "      <th>MinTemp</th>\n",
       "      <th>MeanTemp</th>\n",
       "      <th>Snowfall</th>\n",
       "      <th>PoorWeather</th>\n",
       "      <th>YR</th>\n",
       "      <th>...</th>\n",
       "      <th>FB</th>\n",
       "      <th>FTI</th>\n",
       "      <th>ITH</th>\n",
       "      <th>PGT</th>\n",
       "      <th>TSHDSBRSGF</th>\n",
       "      <th>SD3</th>\n",
       "      <th>RHX</th>\n",
       "      <th>RHN</th>\n",
       "      <th>RVG</th>\n",
       "      <th>WTE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10001</td>\n",
       "      <td>1942-7-1</td>\n",
       "      <td>1.016</td>\n",
       "      <td>NaN</td>\n",
       "      <td>25.555556</td>\n",
       "      <td>22.222222</td>\n",
       "      <td>23.888889</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>42</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10001</td>\n",
       "      <td>1942-7-2</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>28.888889</td>\n",
       "      <td>21.666667</td>\n",
       "      <td>25.555556</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>42</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10001</td>\n",
       "      <td>1942-7-3</td>\n",
       "      <td>2.54</td>\n",
       "      <td>NaN</td>\n",
       "      <td>26.111111</td>\n",
       "      <td>22.222222</td>\n",
       "      <td>24.444444</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>42</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10001</td>\n",
       "      <td>1942-7-4</td>\n",
       "      <td>2.54</td>\n",
       "      <td>NaN</td>\n",
       "      <td>26.666667</td>\n",
       "      <td>22.222222</td>\n",
       "      <td>24.444444</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>42</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10001</td>\n",
       "      <td>1942-7-5</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>26.666667</td>\n",
       "      <td>21.666667</td>\n",
       "      <td>24.444444</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>42</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>10001</td>\n",
       "      <td>1942-7-6</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>26.666667</td>\n",
       "      <td>21.666667</td>\n",
       "      <td>24.444444</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>42</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>10001</td>\n",
       "      <td>1942-7-7</td>\n",
       "      <td>T</td>\n",
       "      <td>NaN</td>\n",
       "      <td>28.333333</td>\n",
       "      <td>22.777778</td>\n",
       "      <td>25.555556</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>42</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>10001</td>\n",
       "      <td>1942-7-8</td>\n",
       "      <td>3.556</td>\n",
       "      <td>NaN</td>\n",
       "      <td>26.666667</td>\n",
       "      <td>22.222222</td>\n",
       "      <td>24.444444</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>42</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>10001</td>\n",
       "      <td>1942-7-9</td>\n",
       "      <td>T</td>\n",
       "      <td>NaN</td>\n",
       "      <td>27.222222</td>\n",
       "      <td>22.777778</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>42</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10001</td>\n",
       "      <td>1942-7-10</td>\n",
       "      <td>3.556</td>\n",
       "      <td>NaN</td>\n",
       "      <td>25.555556</td>\n",
       "      <td>21.666667</td>\n",
       "      <td>23.333333</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>42</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     STA       Date Precip  WindGustSpd    MaxTemp    MinTemp   MeanTemp  \\\n",
       "0  10001   1942-7-1  1.016          NaN  25.555556  22.222222  23.888889   \n",
       "1  10001   1942-7-2      0          NaN  28.888889  21.666667  25.555556   \n",
       "2  10001   1942-7-3   2.54          NaN  26.111111  22.222222  24.444444   \n",
       "3  10001   1942-7-4   2.54          NaN  26.666667  22.222222  24.444444   \n",
       "4  10001   1942-7-5      0          NaN  26.666667  21.666667  24.444444   \n",
       "5  10001   1942-7-6      0          NaN  26.666667  21.666667  24.444444   \n",
       "6  10001   1942-7-7      T          NaN  28.333333  22.777778  25.555556   \n",
       "7  10001   1942-7-8  3.556          NaN  26.666667  22.222222  24.444444   \n",
       "8  10001   1942-7-9      T          NaN  27.222222  22.777778  25.000000   \n",
       "9  10001  1942-7-10  3.556          NaN  25.555556  21.666667  23.333333   \n",
       "\n",
       "  Snowfall PoorWeather  YR  ...  FB  FTI ITH  PGT  TSHDSBRSGF  SD3  RHX  RHN  \\\n",
       "0        0         NaN  42  ... NaN  NaN NaN  NaN         NaN  NaN  NaN  NaN   \n",
       "1        0         NaN  42  ... NaN  NaN NaN  NaN         NaN  NaN  NaN  NaN   \n",
       "2        0         NaN  42  ... NaN  NaN NaN  NaN         NaN  NaN  NaN  NaN   \n",
       "3        0         NaN  42  ... NaN  NaN NaN  NaN         NaN  NaN  NaN  NaN   \n",
       "4        0         NaN  42  ... NaN  NaN NaN  NaN         NaN  NaN  NaN  NaN   \n",
       "5        0         NaN  42  ... NaN  NaN NaN  NaN         NaN  NaN  NaN  NaN   \n",
       "6        0         NaN  42  ... NaN  NaN NaN  NaN         NaN  NaN  NaN  NaN   \n",
       "7        0         NaN  42  ... NaN  NaN NaN  NaN         NaN  NaN  NaN  NaN   \n",
       "8        0         NaN  42  ... NaN  NaN NaN  NaN         NaN  NaN  NaN  NaN   \n",
       "9        0         NaN  42  ... NaN  NaN NaN  NaN         NaN  NaN  NaN  NaN   \n",
       "\n",
       "  RVG  WTE  \n",
       "0 NaN  NaN  \n",
       "1 NaN  NaN  \n",
       "2 NaN  NaN  \n",
       "3 NaN  NaN  \n",
       "4 NaN  NaN  \n",
       "5 NaN  NaN  \n",
       "6 NaN  NaN  \n",
       "7 NaN  NaN  \n",
       "8 NaN  NaN  \n",
       "9 NaN  NaN  \n",
       "\n",
       "[10 rows x 31 columns]"
      ]
     },
     "execution_count": 521,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 522,
   "id": "84c6b890",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1834179"
      ]
     },
     "execution_count": 522,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 523,
   "id": "921e20bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna(axis=1, how='all')\n",
    "df['Date'] = pd.to_datetime(df['Date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 524,
   "id": "09ac4cfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_temp = df.drop(columns=['Date'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "2e2a46ae",
   "metadata": {},
   "source": [
    "invalid values are filled in DataFrame. So, we need to specify which columns contain the invalid values in order to exclude or deal with it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 525,
   "id": "32b2d5df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precip\n",
      "Snowfall\n",
      "PoorWeather\n",
      "PRCP\n",
      "SNF\n",
      "TSHDSBRSGF\n"
     ]
    }
   ],
   "source": [
    "for e in df_temp.columns:\n",
    "    if df_temp[e].dtypes == 'O':\n",
    "        print(e)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "58a02d42",
   "metadata": {},
   "source": [
    "Above columns have multiple types of value in a single column (storing different type in a single column), which give us a sense that it tend to have invalid value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 526,
   "id": "0b2d729a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precip             0\n",
      "Snowfall        1163\n",
      "PoorWeather    84803\n",
      "PRCP            1932\n",
      "SNF             1163\n",
      "TSHDSBRSGF     84803\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "df_temp2 = df_temp[['Precip', 'Snowfall', 'PoorWeather', 'PRCP', 'SNF', 'TSHDSBRSGF']]\n",
    "print(df_temp2.isnull().sum())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f9ce1e62",
   "metadata": {},
   "source": [
    "df_temp2 store suspicious columns that are likely have to be cleaned."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f9799bc5",
   "metadata": {},
   "source": [
    "After apply .astype(float) method for each column, we found that 'PoorWeather' and 'TSHDSBRSGF' columns have multiple invalid values such as '1   1' which are hard to deal with. So, we decided to drop both columns and keep the others."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 527,
   "id": "0767c4b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precip\n",
      "PRCP\n",
      "SNF\n"
     ]
    }
   ],
   "source": [
    "for e in df_temp.columns:\n",
    "    if df_temp[e].astype(str).str.contains('T').any():\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 528,
   "id": "f9055d64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Snowfall\n"
     ]
    }
   ],
   "source": [
    "for e in df_temp.columns:\n",
    "    if df_temp[e].astype(str).str.contains('#VALUE!').any():\n",
    "        print(e)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a6e216bc",
   "metadata": {},
   "source": [
    "These columns contain 'T' or '#VALUE!' which are invalid values. So, I will replace it with np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 529,
   "id": "4a12a231",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_temp = df_temp.drop(columns=['TSHDSBRSGF', 'PoorWeather'])\n",
    "df_temp[['Precip', 'PRCP', 'SNF']] = df_temp[['Precip', 'PRCP', 'SNF']].replace('T', np.nan)\n",
    "df_temp['Snowfall'] = df_temp['Snowfall'].replace('#VALUE!', np.nan)\n",
    "df_temp = df_temp.astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 530,
   "id": "7002de53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 119040 entries, 0 to 119039\n",
      "Data columns (total 19 columns):\n",
      " #   Column       Non-Null Count   Dtype  \n",
      "---  ------       --------------   -----  \n",
      " 0   STA          119040 non-null  float64\n",
      " 1   Precip       102287 non-null  float64\n",
      " 2   WindGustSpd  532 non-null     float64\n",
      " 3   MaxTemp      119040 non-null  float64\n",
      " 4   MinTemp      119040 non-null  float64\n",
      " 5   MeanTemp     119040 non-null  float64\n",
      " 6   Snowfall     117833 non-null  float64\n",
      " 7   YR           119040 non-null  float64\n",
      " 8   MO           119040 non-null  float64\n",
      " 9   DA           119040 non-null  float64\n",
      " 10  PRCP         100355 non-null  float64\n",
      " 11  DR           533 non-null     float64\n",
      " 12  SPD          532 non-null     float64\n",
      " 13  MAX          118566 non-null  float64\n",
      " 14  MIN          118572 non-null  float64\n",
      " 15  MEA          118542 non-null  float64\n",
      " 16  SNF          117833 non-null  float64\n",
      " 17  SND          5563 non-null    float64\n",
      " 18  PGT          525 non-null     float64\n",
      "dtypes: float64(19)\n",
      "memory usage: 17.3 MB\n"
     ]
    }
   ],
   "source": [
    "df_temp.info()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "1fa5c748",
   "metadata": {},
   "source": [
    "### Fill missing values"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "21c10f9f",
   "metadata": {},
   "source": [
    "Before we're going to fill missing value, we have to decide what we're going to fill it with such as mean, median (mode won't be used in this case). So, we will use MinMaxScaler to preserve and observe its distribution. If the column contain SOME of outliers, using a mean of that column wouldn't be appropriate because the mean value would be affected too much by outliers, so we will use median instead. On the other hand, if the column contain NO OULIER or SIGNIFICANT MULTIPLE OF OUTLIERs, we will use mean in order to fill missing value with the most general or nature of the column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 531,
   "id": "9f07a477",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>STA</th>\n",
       "      <th>Precip</th>\n",
       "      <th>WindGustSpd</th>\n",
       "      <th>MaxTemp</th>\n",
       "      <th>MinTemp</th>\n",
       "      <th>MeanTemp</th>\n",
       "      <th>Snowfall</th>\n",
       "      <th>YR</th>\n",
       "      <th>MO</th>\n",
       "      <th>DA</th>\n",
       "      <th>PRCP</th>\n",
       "      <th>DR</th>\n",
       "      <th>SPD</th>\n",
       "      <th>MAX</th>\n",
       "      <th>MIN</th>\n",
       "      <th>MEA</th>\n",
       "      <th>SNF</th>\n",
       "      <th>SND</th>\n",
       "      <th>PGT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.003306</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.706667</td>\n",
       "      <td>0.832061</td>\n",
       "      <td>0.786765</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.545455</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.003306</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.706667</td>\n",
       "      <td>0.832061</td>\n",
       "      <td>0.786765</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.746667</td>\n",
       "      <td>0.824427</td>\n",
       "      <td>0.808824</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.545455</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.746667</td>\n",
       "      <td>0.824427</td>\n",
       "      <td>0.808824</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.008264</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.713333</td>\n",
       "      <td>0.832061</td>\n",
       "      <td>0.794118</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.545455</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.008264</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.713333</td>\n",
       "      <td>0.832061</td>\n",
       "      <td>0.794118</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.008264</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.720000</td>\n",
       "      <td>0.832061</td>\n",
       "      <td>0.794118</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.545455</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.008264</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.720000</td>\n",
       "      <td>0.832061</td>\n",
       "      <td>0.794118</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.720000</td>\n",
       "      <td>0.824427</td>\n",
       "      <td>0.794118</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.545455</td>\n",
       "      <td>0.133333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.720000</td>\n",
       "      <td>0.824427</td>\n",
       "      <td>0.794118</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119035</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.740000</td>\n",
       "      <td>0.778626</td>\n",
       "      <td>0.779412</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.866667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.740000</td>\n",
       "      <td>0.778626</td>\n",
       "      <td>0.779412</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119036</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.032231</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.753333</td>\n",
       "      <td>0.778626</td>\n",
       "      <td>0.786765</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.032231</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.753333</td>\n",
       "      <td>0.778626</td>\n",
       "      <td>0.786765</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119037</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.740000</td>\n",
       "      <td>0.778626</td>\n",
       "      <td>0.779412</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.740000</td>\n",
       "      <td>0.778626</td>\n",
       "      <td>0.779412</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119038</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.740000</td>\n",
       "      <td>0.778626</td>\n",
       "      <td>0.779412</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.966667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.740000</td>\n",
       "      <td>0.778626</td>\n",
       "      <td>0.779412</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119039</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.753333</td>\n",
       "      <td>0.763359</td>\n",
       "      <td>0.779412</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.753333</td>\n",
       "      <td>0.763359</td>\n",
       "      <td>0.779412</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>119040 rows × 19 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        STA    Precip  WindGustSpd   MaxTemp   MinTemp  MeanTemp  Snowfall  \\\n",
       "0       0.0  0.003306          NaN  0.706667  0.832061  0.786765       0.0   \n",
       "1       0.0  0.000000          NaN  0.746667  0.824427  0.808824       0.0   \n",
       "2       0.0  0.008264          NaN  0.713333  0.832061  0.794118       0.0   \n",
       "3       0.0  0.008264          NaN  0.720000  0.832061  0.794118       0.0   \n",
       "4       0.0  0.000000          NaN  0.720000  0.824427  0.794118       0.0   \n",
       "...     ...       ...          ...       ...       ...       ...       ...   \n",
       "119035  1.0  0.000000          NaN  0.740000  0.778626  0.779412       0.0   \n",
       "119036  1.0  0.032231          NaN  0.753333  0.778626  0.786765       0.0   \n",
       "119037  1.0  0.000000          NaN  0.740000  0.778626  0.779412       0.0   \n",
       "119038  1.0  0.000000          NaN  0.740000  0.778626  0.779412       0.0   \n",
       "119039  1.0  0.000000          NaN  0.753333  0.763359  0.779412       0.0   \n",
       "\n",
       "         YR        MO        DA      PRCP  DR  SPD       MAX       MIN  \\\n",
       "0       0.4  0.545455  0.000000  0.003306 NaN  NaN  0.706667  0.832061   \n",
       "1       0.4  0.545455  0.033333  0.000000 NaN  NaN  0.746667  0.824427   \n",
       "2       0.4  0.545455  0.066667  0.008264 NaN  NaN  0.713333  0.832061   \n",
       "3       0.4  0.545455  0.100000  0.008264 NaN  NaN  0.720000  0.832061   \n",
       "4       0.4  0.545455  0.133333  0.000000 NaN  NaN  0.720000  0.824427   \n",
       "...     ...       ...       ...       ...  ..  ...       ...       ...   \n",
       "119035  1.0  1.000000  0.866667  0.000000 NaN  NaN  0.740000  0.778626   \n",
       "119036  1.0  1.000000  0.900000  0.032231 NaN  NaN  0.753333  0.778626   \n",
       "119037  1.0  1.000000  0.933333  0.000000 NaN  NaN  0.740000  0.778626   \n",
       "119038  1.0  1.000000  0.966667  0.000000 NaN  NaN  0.740000  0.778626   \n",
       "119039  1.0  1.000000  1.000000  0.000000 NaN  NaN  0.753333  0.763359   \n",
       "\n",
       "             MEA  SNF  SND  PGT  \n",
       "0       0.786765  0.0  NaN  NaN  \n",
       "1       0.808824  0.0  NaN  NaN  \n",
       "2       0.794118  0.0  NaN  NaN  \n",
       "3       0.794118  0.0  NaN  NaN  \n",
       "4       0.794118  0.0  NaN  NaN  \n",
       "...          ...  ...  ...  ...  \n",
       "119035  0.779412  0.0  NaN  NaN  \n",
       "119036  0.786765  0.0  NaN  NaN  \n",
       "119037  0.779412  0.0  NaN  NaN  \n",
       "119038  0.779412  0.0  NaN  NaN  \n",
       "119039  0.779412  0.0  NaN  NaN  \n",
       "\n",
       "[119040 rows x 19 columns]"
      ]
     },
     "execution_count": 531,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min_max_scaler = MinMaxScaler()\n",
    "df_temp2 = pd.DataFrame(min_max_scaler.fit_transform(df_temp))\n",
    "df_temp2.columns = list(df_temp.columns)\n",
    "df_temp2"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "04f38b67",
   "metadata": {},
   "source": [
    "P.S. df_temp2 in only used for observing distribution to decide method of imputation. Now, we still hold on df_temp as main a DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 532,
   "id": "43b7bfd7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 532,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1600x900 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure(figsize=(16, 9))\n",
    "df_temp2.boxplot()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "2c97e818",
   "metadata": {},
   "source": [
    "From boxplot above, we're able to decide which columns should be filled na with 'mean' or 'median'. The one that has **low amount of outliers** will be filled na with 'median', and the other will be 'mean'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 533,
   "id": "b489e6e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0    5563\n",
       "Name: SND, dtype: int64"
      ]
     },
     "execution_count": 533,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_temp['SND'].value_counts()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e6dd2567",
   "metadata": {},
   "source": [
    "From boxplot and describe() method, column 'SND' quite doesn't make sense to take into ML model due to duplicated values 0 and NaN. So drop off the column would be better. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 534,
   "id": "7e1aa8be",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_temp5 = df_temp.drop(columns=['SND'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "7077b35d",
   "metadata": {},
   "source": [
    "> Notice that *df_temp5* is a DataFrame before filling missing value but already cleaned at a step. We will use *df_temp5* later in other aspect of developing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 535,
   "id": "36463f81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# will be filled with median\n",
    "df_temp3 = df_temp5[['STA', 'WindGustSpd', 'DR', 'SPD']]\n",
    "\n",
    "# will be filled with mean\n",
    "df_temp4 = df_temp5.drop(['STA', 'WindGustSpd', 'DR', 'SPD'], axis=1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "608f6bf4",
   "metadata": {},
   "source": [
    "fill missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 536,
   "id": "7c46b971",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.mode.chained_assignment = None  # default='warn'\n",
    "\n",
    "for col in df_temp3.columns:\n",
    "    df_temp3[col] = df_temp3[col].fillna(df_temp3[col].median())\n",
    "for col in df_temp4.columns:\n",
    "    df_temp4[col] = df_temp4[col].fillna(df_temp4[col].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 537,
   "id": "bbbb935e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STA            0\n",
      "WindGustSpd    0\n",
      "DR             0\n",
      "SPD            0\n",
      "dtype: int64\n",
      "Precip      0\n",
      "MaxTemp     0\n",
      "MinTemp     0\n",
      "MeanTemp    0\n",
      "Snowfall    0\n",
      "YR          0\n",
      "MO          0\n",
      "DA          0\n",
      "PRCP        0\n",
      "MAX         0\n",
      "MIN         0\n",
      "MEA         0\n",
      "SNF         0\n",
      "PGT         0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df_temp3.isnull().sum())\n",
    "print(df_temp4.isnull().sum())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "748d5f9f",
   "metadata": {},
   "source": [
    "Both type columns are filled, next we will concatenate or aggregate into a DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 538,
   "id": "e68bfb9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_temp = pd.concat([df_temp3, df_temp4], axis=1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "3d7d800a",
   "metadata": {},
   "source": [
    "And also insert column *'Date'* as it had before. Then, we're going back to use df instead of df_temp as our main DataFrame which is already cleaned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 539,
   "id": "a0127e52",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>STA</th>\n",
       "      <th>WindGustSpd</th>\n",
       "      <th>DR</th>\n",
       "      <th>SPD</th>\n",
       "      <th>Precip</th>\n",
       "      <th>MaxTemp</th>\n",
       "      <th>MinTemp</th>\n",
       "      <th>MeanTemp</th>\n",
       "      <th>Snowfall</th>\n",
       "      <th>YR</th>\n",
       "      <th>MO</th>\n",
       "      <th>DA</th>\n",
       "      <th>PRCP</th>\n",
       "      <th>MAX</th>\n",
       "      <th>MIN</th>\n",
       "      <th>MEA</th>\n",
       "      <th>SNF</th>\n",
       "      <th>PGT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1942-07-01</td>\n",
       "      <td>10001.0</td>\n",
       "      <td>37.04</td>\n",
       "      <td>32.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>1.016</td>\n",
       "      <td>25.555556</td>\n",
       "      <td>22.222222</td>\n",
       "      <td>23.888889</td>\n",
       "      <td>0.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.04</td>\n",
       "      <td>78.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.085333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1942-07-02</td>\n",
       "      <td>10001.0</td>\n",
       "      <td>37.04</td>\n",
       "      <td>32.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>28.888889</td>\n",
       "      <td>21.666667</td>\n",
       "      <td>25.555556</td>\n",
       "      <td>0.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>84.0</td>\n",
       "      <td>71.0</td>\n",
       "      <td>78.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.085333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1942-07-03</td>\n",
       "      <td>10001.0</td>\n",
       "      <td>37.04</td>\n",
       "      <td>32.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>2.540</td>\n",
       "      <td>26.111111</td>\n",
       "      <td>22.222222</td>\n",
       "      <td>24.444444</td>\n",
       "      <td>0.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.10</td>\n",
       "      <td>79.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.085333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1942-07-04</td>\n",
       "      <td>10001.0</td>\n",
       "      <td>37.04</td>\n",
       "      <td>32.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>2.540</td>\n",
       "      <td>26.666667</td>\n",
       "      <td>22.222222</td>\n",
       "      <td>24.444444</td>\n",
       "      <td>0.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.10</td>\n",
       "      <td>80.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.085333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1942-07-05</td>\n",
       "      <td>10001.0</td>\n",
       "      <td>37.04</td>\n",
       "      <td>32.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>26.666667</td>\n",
       "      <td>21.666667</td>\n",
       "      <td>24.444444</td>\n",
       "      <td>0.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>80.0</td>\n",
       "      <td>71.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.085333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119035</th>\n",
       "      <td>1945-12-27</td>\n",
       "      <td>82506.0</td>\n",
       "      <td>37.04</td>\n",
       "      <td>32.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>28.333333</td>\n",
       "      <td>18.333333</td>\n",
       "      <td>23.333333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>83.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.085333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119036</th>\n",
       "      <td>1945-12-28</td>\n",
       "      <td>82506.0</td>\n",
       "      <td>37.04</td>\n",
       "      <td>32.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>9.906</td>\n",
       "      <td>29.444444</td>\n",
       "      <td>18.333333</td>\n",
       "      <td>23.888889</td>\n",
       "      <td>0.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0.39</td>\n",
       "      <td>85.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.085333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119037</th>\n",
       "      <td>1945-12-29</td>\n",
       "      <td>82506.0</td>\n",
       "      <td>37.04</td>\n",
       "      <td>32.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>28.333333</td>\n",
       "      <td>18.333333</td>\n",
       "      <td>23.333333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>83.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.085333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119038</th>\n",
       "      <td>1945-12-30</td>\n",
       "      <td>82506.0</td>\n",
       "      <td>37.04</td>\n",
       "      <td>32.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>28.333333</td>\n",
       "      <td>18.333333</td>\n",
       "      <td>23.333333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>83.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.085333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119039</th>\n",
       "      <td>1945-12-31</td>\n",
       "      <td>82506.0</td>\n",
       "      <td>37.04</td>\n",
       "      <td>32.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>29.444444</td>\n",
       "      <td>17.222222</td>\n",
       "      <td>23.333333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>85.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.085333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>119040 rows × 19 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             Date      STA  WindGustSpd    DR   SPD  Precip    MaxTemp  \\\n",
       "0      1942-07-01  10001.0        37.04  32.0  20.0   1.016  25.555556   \n",
       "1      1942-07-02  10001.0        37.04  32.0  20.0   0.000  28.888889   \n",
       "2      1942-07-03  10001.0        37.04  32.0  20.0   2.540  26.111111   \n",
       "3      1942-07-04  10001.0        37.04  32.0  20.0   2.540  26.666667   \n",
       "4      1942-07-05  10001.0        37.04  32.0  20.0   0.000  26.666667   \n",
       "...           ...      ...          ...   ...   ...     ...        ...   \n",
       "119035 1945-12-27  82506.0        37.04  32.0  20.0   0.000  28.333333   \n",
       "119036 1945-12-28  82506.0        37.04  32.0  20.0   9.906  29.444444   \n",
       "119037 1945-12-29  82506.0        37.04  32.0  20.0   0.000  28.333333   \n",
       "119038 1945-12-30  82506.0        37.04  32.0  20.0   0.000  28.333333   \n",
       "119039 1945-12-31  82506.0        37.04  32.0  20.0   0.000  29.444444   \n",
       "\n",
       "          MinTemp   MeanTemp  Snowfall    YR    MO    DA  PRCP   MAX   MIN  \\\n",
       "0       22.222222  23.888889       0.0  42.0   7.0   1.0  0.04  78.0  72.0   \n",
       "1       21.666667  25.555556       0.0  42.0   7.0   2.0  0.00  84.0  71.0   \n",
       "2       22.222222  24.444444       0.0  42.0   7.0   3.0  0.10  79.0  72.0   \n",
       "3       22.222222  24.444444       0.0  42.0   7.0   4.0  0.10  80.0  72.0   \n",
       "4       21.666667  24.444444       0.0  42.0   7.0   5.0  0.00  80.0  71.0   \n",
       "...           ...        ...       ...   ...   ...   ...   ...   ...   ...   \n",
       "119035  18.333333  23.333333       0.0  45.0  12.0  27.0  0.00  83.0  65.0   \n",
       "119036  18.333333  23.888889       0.0  45.0  12.0  28.0  0.39  85.0  65.0   \n",
       "119037  18.333333  23.333333       0.0  45.0  12.0  29.0  0.00  83.0  65.0   \n",
       "119038  18.333333  23.333333       0.0  45.0  12.0  30.0  0.00  83.0  65.0   \n",
       "119039  17.222222  23.333333       0.0  45.0  12.0  31.0  0.00  85.0  63.0   \n",
       "\n",
       "         MEA  SNF        PGT  \n",
       "0       75.0  0.0  12.085333  \n",
       "1       78.0  0.0  12.085333  \n",
       "2       76.0  0.0  12.085333  \n",
       "3       76.0  0.0  12.085333  \n",
       "4       76.0  0.0  12.085333  \n",
       "...      ...  ...        ...  \n",
       "119035  74.0  0.0  12.085333  \n",
       "119036  75.0  0.0  12.085333  \n",
       "119037  74.0  0.0  12.085333  \n",
       "119038  74.0  0.0  12.085333  \n",
       "119039  74.0  0.0  12.085333  \n",
       "\n",
       "[119040 rows x 19 columns]"
      ]
     },
     "execution_count": 539,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_temp.insert(loc=0, column='Date', value=df['Date'])\n",
    "df = df_temp\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 540,
   "id": "a9c93efd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>STA</th>\n",
       "      <th>WindGustSpd</th>\n",
       "      <th>DR</th>\n",
       "      <th>SPD</th>\n",
       "      <th>Precip</th>\n",
       "      <th>MaxTemp</th>\n",
       "      <th>MinTemp</th>\n",
       "      <th>MeanTemp</th>\n",
       "      <th>Snowfall</th>\n",
       "      <th>YR</th>\n",
       "      <th>MO</th>\n",
       "      <th>DA</th>\n",
       "      <th>PRCP</th>\n",
       "      <th>MAX</th>\n",
       "      <th>MIN</th>\n",
       "      <th>MEA</th>\n",
       "      <th>SNF</th>\n",
       "      <th>PGT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>119040.000000</td>\n",
       "      <td>119040.000000</td>\n",
       "      <td>119040.000000</td>\n",
       "      <td>119040.000000</td>\n",
       "      <td>119040.000000</td>\n",
       "      <td>119040.000000</td>\n",
       "      <td>119040.000000</td>\n",
       "      <td>119040.000000</td>\n",
       "      <td>119040.000000</td>\n",
       "      <td>119040.000000</td>\n",
       "      <td>119040.000000</td>\n",
       "      <td>119040.000000</td>\n",
       "      <td>119040.000000</td>\n",
       "      <td>119040.000000</td>\n",
       "      <td>119040.000000</td>\n",
       "      <td>119040.000000</td>\n",
       "      <td>119040.000000</td>\n",
       "      <td>119040.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>29659.435795</td>\n",
       "      <td>37.043283</td>\n",
       "      <td>31.977604</td>\n",
       "      <td>20.001773</td>\n",
       "      <td>3.753917</td>\n",
       "      <td>27.045111</td>\n",
       "      <td>17.789511</td>\n",
       "      <td>22.411631</td>\n",
       "      <td>0.245544</td>\n",
       "      <td>43.805284</td>\n",
       "      <td>6.726016</td>\n",
       "      <td>15.797530</td>\n",
       "      <td>0.150637</td>\n",
       "      <td>81.003745</td>\n",
       "      <td>64.273808</td>\n",
       "      <td>72.644843</td>\n",
       "      <td>0.009667</td>\n",
       "      <td>12.085333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>20953.209402</td>\n",
       "      <td>0.689520</td>\n",
       "      <td>1.070991</td>\n",
       "      <td>0.372311</td>\n",
       "      <td>10.721867</td>\n",
       "      <td>8.717817</td>\n",
       "      <td>8.334572</td>\n",
       "      <td>8.297982</td>\n",
       "      <td>2.613250</td>\n",
       "      <td>1.136718</td>\n",
       "      <td>3.425561</td>\n",
       "      <td>8.794541</td>\n",
       "      <td>0.421693</td>\n",
       "      <td>14.839727</td>\n",
       "      <td>14.453003</td>\n",
       "      <td>14.181324</td>\n",
       "      <td>0.102884</td>\n",
       "      <td>0.380256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>10001.000000</td>\n",
       "      <td>18.520000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-33.333333</td>\n",
       "      <td>-38.333333</td>\n",
       "      <td>-35.555556</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>40.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-28.000000</td>\n",
       "      <td>-37.000000</td>\n",
       "      <td>-32.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>11801.000000</td>\n",
       "      <td>37.040000</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>25.555556</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>20.555556</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>43.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>78.000000</td>\n",
       "      <td>59.000000</td>\n",
       "      <td>69.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>12.085333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>22508.000000</td>\n",
       "      <td>37.040000</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>29.444444</td>\n",
       "      <td>21.111111</td>\n",
       "      <td>25.555556</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>44.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>85.000000</td>\n",
       "      <td>70.000000</td>\n",
       "      <td>78.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>12.085333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>33501.000000</td>\n",
       "      <td>37.040000</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>3.753917</td>\n",
       "      <td>31.666667</td>\n",
       "      <td>23.333333</td>\n",
       "      <td>27.222222</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>45.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>0.150637</td>\n",
       "      <td>89.000000</td>\n",
       "      <td>74.000000</td>\n",
       "      <td>81.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>12.085333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>82506.000000</td>\n",
       "      <td>75.932000</td>\n",
       "      <td>78.000000</td>\n",
       "      <td>41.000000</td>\n",
       "      <td>307.340000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>34.444444</td>\n",
       "      <td>40.000000</td>\n",
       "      <td>86.360000</td>\n",
       "      <td>45.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>31.000000</td>\n",
       "      <td>12.100000</td>\n",
       "      <td>122.000000</td>\n",
       "      <td>94.000000</td>\n",
       "      <td>104.000000</td>\n",
       "      <td>3.400000</td>\n",
       "      <td>23.900000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 STA    WindGustSpd             DR            SPD  \\\n",
       "count  119040.000000  119040.000000  119040.000000  119040.000000   \n",
       "mean    29659.435795      37.043283      31.977604      20.001773   \n",
       "std     20953.209402       0.689520       1.070991       0.372311   \n",
       "min     10001.000000      18.520000       2.000000      10.000000   \n",
       "25%     11801.000000      37.040000      32.000000      20.000000   \n",
       "50%     22508.000000      37.040000      32.000000      20.000000   \n",
       "75%     33501.000000      37.040000      32.000000      20.000000   \n",
       "max     82506.000000      75.932000      78.000000      41.000000   \n",
       "\n",
       "              Precip        MaxTemp        MinTemp       MeanTemp  \\\n",
       "count  119040.000000  119040.000000  119040.000000  119040.000000   \n",
       "mean        3.753917      27.045111      17.789511      22.411631   \n",
       "std        10.721867       8.717817       8.334572       8.297982   \n",
       "min         0.000000     -33.333333     -38.333333     -35.555556   \n",
       "25%         0.000000      25.555556      15.000000      20.555556   \n",
       "50%         0.000000      29.444444      21.111111      25.555556   \n",
       "75%         3.753917      31.666667      23.333333      27.222222   \n",
       "max       307.340000      50.000000      34.444444      40.000000   \n",
       "\n",
       "            Snowfall             YR             MO             DA  \\\n",
       "count  119040.000000  119040.000000  119040.000000  119040.000000   \n",
       "mean        0.245544      43.805284       6.726016      15.797530   \n",
       "std         2.613250       1.136718       3.425561       8.794541   \n",
       "min         0.000000      40.000000       1.000000       1.000000   \n",
       "25%         0.000000      43.000000       4.000000       8.000000   \n",
       "50%         0.000000      44.000000       7.000000      16.000000   \n",
       "75%         0.000000      45.000000      10.000000      23.000000   \n",
       "max        86.360000      45.000000      12.000000      31.000000   \n",
       "\n",
       "                PRCP            MAX            MIN            MEA  \\\n",
       "count  119040.000000  119040.000000  119040.000000  119040.000000   \n",
       "mean        0.150637      81.003745      64.273808      72.644843   \n",
       "std         0.421693      14.839727      14.453003      14.181324   \n",
       "min         0.000000     -28.000000     -37.000000     -32.000000   \n",
       "25%         0.000000      78.000000      59.000000      69.000000   \n",
       "50%         0.000000      85.000000      70.000000      78.000000   \n",
       "75%         0.150637      89.000000      74.000000      81.000000   \n",
       "max        12.100000     122.000000      94.000000     104.000000   \n",
       "\n",
       "                 SNF            PGT  \n",
       "count  119040.000000  119040.000000  \n",
       "mean        0.009667      12.085333  \n",
       "std         0.102884       0.380256  \n",
       "min         0.000000       0.000000  \n",
       "25%         0.000000      12.085333  \n",
       "50%         0.000000      12.085333  \n",
       "75%         0.000000      12.085333  \n",
       "max         3.400000      23.900000  "
      ]
     },
     "execution_count": 540,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "6d70462c",
   "metadata": {},
   "source": [
    "Define Input and Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 541,
   "id": "020d9b58",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data(df):\n",
    "    Y = df[['Date', 'MaxTemp', 'MinTemp', 'MeanTemp']]\n",
    "    X = df.drop(columns=['MaxTemp', 'MinTemp', 'MeanTemp'])\n",
    "\n",
    "    X = X.set_index('Date')\n",
    "    Y = Y.set_index('Date')\n",
    "\n",
    "    # test size = 0.2\n",
    "    cutoff = int(df.shape[0]*0.8)\n",
    "\n",
    "    X_train = df.loc[:cutoff, X.columns]\n",
    "    y_train = df.loc[:cutoff, Y.columns]\n",
    "\n",
    "    X_test = df.loc[cutoff:, X.columns]\n",
    "    y_test = df.loc[cutoff:, Y.columns]\n",
    "\n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 542,
   "id": "3877a84f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(95233, 15) (95233, 3) (23808, 15) (23808, 3)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = split_data(df)\n",
    "print(X_train.shape, y_train.shape, X_test.shape, y_test.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "367e35d6",
   "metadata": {},
   "source": [
    "## Model Development\n",
    "*Model: RandomForestRegressor*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 543,
   "id": "97add721",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RandomForestRegressor()\n",
    "\n",
    "param_grid = [{\n",
    "    'n_estimators': [100, 200, 300, 400],\n",
    "    'criterion': ['squared_error', 'absolute_error'],\n",
    "    'max_depth': [3, 4, 5, 6],\n",
    "    'max_features': ['sqrt', 'log2'],\n",
    "    'bootstrap': [True],\n",
    "    'random_state': [1]\n",
    "}]\n",
    "\n",
    "rand = RandomizedSearchCV(model, param_distributions=param_grid)\n",
    "grid = GridSearchCV(model, param_grid=param_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 544,
   "id": "853099a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "t0 = time()\n",
    "# grid.fit(X_train, y_train)\n",
    "print(time()-t0)\n",
    "\n",
    "t0 = time()\n",
    "# rand.fit(X_train, y_train)\n",
    "print(time()-t0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 545,
   "id": "ac204d25",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-22 {color: black;background-color: white;}#sk-container-id-22 pre{padding: 0;}#sk-container-id-22 div.sk-toggleable {background-color: white;}#sk-container-id-22 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-22 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-22 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-22 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-22 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-22 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-22 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-22 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-22 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-22 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-22 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-22 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-22 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-22 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-22 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-22 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-22 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-22 div.sk-item {position: relative;z-index: 1;}#sk-container-id-22 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-22 div.sk-item::before, #sk-container-id-22 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-22 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-22 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-22 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-22 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-22 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-22 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-22 div.sk-label-container {text-align: center;}#sk-container-id-22 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-22 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-22\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestRegressor(max_depth=4, max_features=&#x27;sqrt&#x27;, random_state=1)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-22\" type=\"checkbox\" checked><label for=\"sk-estimator-id-22\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestRegressor</label><div class=\"sk-toggleable__content\"><pre>RandomForestRegressor(max_depth=4, max_features=&#x27;sqrt&#x27;, random_state=1)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestRegressor(max_depth=4, max_features='sqrt', random_state=1)"
      ]
     },
     "execution_count": 545,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = RandomForestRegressor(n_estimators=100, criterion='squared_error', max_depth=4, max_features='sqrt', bootstrap=True, random_state=1)\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 546,
   "id": "f126cbe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_predict_score(y_test, prediction):\n",
    "    r2 = r2_score(y_test, prediction)\n",
    "    mse = mean_squared_error(y_test, prediction)\n",
    "    mae = mean_absolute_error(y_test, prediction)\n",
    "\n",
    "    print('r2: ', r2, '\\n', 'mse: ', mse, '\\n', 'mae: ', mae)\n",
    "    return r2, mse, mae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 547,
   "id": "271c7e19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score on test set\n",
      "r2:  0.7717823464712087 \n",
      " mse:  5.191191853921098 \n",
      " mae:  1.5870862904809122\n"
     ]
    }
   ],
   "source": [
    "prediction = model.predict(X_test)\n",
    "print('score on test set')\n",
    "r2_1_test, mse_1_test, mae_1_test = make_predict_score(y_test, prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 548,
   "id": "a404e0a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score on train set\n",
      "r2:  0.8911132056566141 \n",
      " mse:  8.97948296348254 \n",
      " mae:  1.7488587839166982\n"
     ]
    }
   ],
   "source": [
    "prediction = model.predict(X_train)\n",
    "print('score on train set')\n",
    "r2_1_train, mse_1_train, mae_1_train = make_predict_score(y_train, prediction)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f4082c20",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f5534651",
   "metadata": {},
   "source": [
    "## Other approaches of ML developing"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "1e41b05b",
   "metadata": {},
   "source": [
    "### Multivariate feature imputation (IterativeImputor)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "1b14c046",
   "metadata": {},
   "source": [
    "Using IterativeImputor is a more sophisticated approach to fill missing values, but instead it's harder to explain its algorithm, formula, or associated fucnction. Read more about the Multivariate Imputation's algorithm [here.](https://cran.r-project.org/web/packages/miceRanger/vignettes/miceAlgorithm.html)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "bf408d00",
   "metadata": {},
   "source": [
    "Using Multivariate feature imputation (IterativeImputer), and scaler for an another approach, start from the point before we filled missing value (df_temp5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 549,
   "id": "31cb9780",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "STA                 0\n",
       "Precip          16753\n",
       "WindGustSpd    118508\n",
       "MaxTemp             0\n",
       "MinTemp             0\n",
       "MeanTemp            0\n",
       "Snowfall         1207\n",
       "YR                  0\n",
       "MO                  0\n",
       "DA                  0\n",
       "PRCP            18685\n",
       "DR             118507\n",
       "SPD            118508\n",
       "MAX               474\n",
       "MIN               468\n",
       "MEA               498\n",
       "SNF              1207\n",
       "PGT            118515\n",
       "dtype: int64"
      ]
     },
     "execution_count": 549,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_temp5.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 550,
   "id": "b7532b38",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\HP\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\impute\\_iterative.py:713: ConvergenceWarning: [IterativeImputer] Early stopping criterion not reached.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "imp = IterativeImputer(random_state=1)\n",
    "array_temp = imp.fit_transform(df_temp5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 551,
   "id": "a055238a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.00010000e+04, 1.01600000e+00, 3.77756305e+01, ...,\n",
       "        7.50000000e+01, 0.00000000e+00, 1.43335731e+01],\n",
       "       [1.00010000e+04, 0.00000000e+00, 3.77756305e+01, ...,\n",
       "        7.80000000e+01, 0.00000000e+00, 1.43323900e+01],\n",
       "       [1.00010000e+04, 2.54000000e+00, 3.77756305e+01, ...,\n",
       "        7.60000000e+01, 0.00000000e+00, 1.43340132e+01],\n",
       "       ...,\n",
       "       [8.25060000e+04, 0.00000000e+00, 3.77745338e+01, ...,\n",
       "        7.40000000e+01, 0.00000000e+00, 3.32728025e+00],\n",
       "       [8.25060000e+04, 0.00000000e+00, 3.77745338e+01, ...,\n",
       "        7.40000000e+01, 0.00000000e+00, 3.32727830e+00],\n",
       "       [8.25060000e+04, 0.00000000e+00, 3.77745338e+01, ...,\n",
       "        7.40000000e+01, 0.00000000e+00, 3.32752208e+00]])"
      ]
     },
     "execution_count": 551,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "array_temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 552,
   "id": "5fed831d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "119040"
      ]
     },
     "execution_count": 552,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(array_temp)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "49e4b9eb",
   "metadata": {},
   "source": [
    "The result from IterativeImputer gave us array type so we need to convert to dataFrame form."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 553,
   "id": "6906944d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_temp = pd.DataFrame(\n",
    "    data = array_temp,\n",
    "    index = df_temp5.index,\n",
    "    columns = df_temp5.columns\n",
    ")\n",
    "df_temp.insert(loc=0, column='Date', value=df['Date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 554,
   "id": "2ed07d9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(95233, 15) (23808, 15) (95233, 3) (23808, 3)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = split_data(df_temp)\n",
    "print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 555,
   "id": "ac204d25",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-23 {color: black;background-color: white;}#sk-container-id-23 pre{padding: 0;}#sk-container-id-23 div.sk-toggleable {background-color: white;}#sk-container-id-23 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-23 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-23 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-23 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-23 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-23 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-23 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-23 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-23 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-23 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-23 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-23 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-23 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-23 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-23 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-23 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-23 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-23 div.sk-item {position: relative;z-index: 1;}#sk-container-id-23 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-23 div.sk-item::before, #sk-container-id-23 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-23 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-23 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-23 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-23 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-23 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-23 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-23 div.sk-label-container {text-align: center;}#sk-container-id-23 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-23 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-23\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestRegressor(max_depth=4, max_features=&#x27;sqrt&#x27;, random_state=1)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-23\" type=\"checkbox\" checked><label for=\"sk-estimator-id-23\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestRegressor</label><div class=\"sk-toggleable__content\"><pre>RandomForestRegressor(max_depth=4, max_features=&#x27;sqrt&#x27;, random_state=1)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestRegressor(max_depth=4, max_features='sqrt', random_state=1)"
      ]
     },
     "execution_count": 555,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = RandomForestRegressor(n_estimators=100, criterion='squared_error', max_depth=4, max_features='sqrt', bootstrap=True, random_state=1)\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 556,
   "id": "271c7e19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score on test set\n",
      "r2:  0.7978878289313057 \n",
      " mse:  4.7499331010794945 \n",
      " mae:  1.6578994633248723\n"
     ]
    }
   ],
   "source": [
    "prediction = model.predict(X_test)\n",
    "print('score on test set')\n",
    "r2_2_test, mse_2_test, mae_2_test = make_predict_score(y_test, prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 557,
   "id": "a404e0a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score on train set\n",
      "r2:  0.9343439613514807 \n",
      " mse:  5.416664036306922 \n",
      " mae:  1.6383403801277805\n"
     ]
    }
   ],
   "source": [
    "prediction = model.predict(X_train)\n",
    "print('score on train set')\n",
    "r2_2_train, mse_2_train, mae_2_train = make_predict_score(y_train, prediction)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "11a1cf21",
   "metadata": {},
   "source": [
    "Comparing performance by Imputer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 558,
   "id": "1d4f0a8f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>R-squared</th>\n",
       "      <th>MSE</th>\n",
       "      <th>MAE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>traditional method on test set</th>\n",
       "      <td>0.771782</td>\n",
       "      <td>5.191192</td>\n",
       "      <td>1.587086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>traditional method on train set</th>\n",
       "      <td>0.891113</td>\n",
       "      <td>8.979483</td>\n",
       "      <td>1.748859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>IterativeImputer method on test set</th>\n",
       "      <td>0.797888</td>\n",
       "      <td>4.749933</td>\n",
       "      <td>1.657899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>IterativeImputer method on train set</th>\n",
       "      <td>0.934344</td>\n",
       "      <td>5.416664</td>\n",
       "      <td>1.638340</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      R-squared       MSE       MAE\n",
       "traditional method on test set         0.771782  5.191192  1.587086\n",
       "traditional method on train set        0.891113  8.979483  1.748859\n",
       "IterativeImputer method on test set    0.797888  4.749933  1.657899\n",
       "IterativeImputer method on train set   0.934344  5.416664  1.638340"
      ]
     },
     "execution_count": 558,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comparing_score = {\n",
    "    'R-squared': [r2_1_test, r2_1_train, r2_2_test, r2_2_train],\n",
    "    'MSE': [mse_1_test, mse_1_train, mse_2_test, mse_2_train],\n",
    "    'MAE': [mae_1_test, mae_1_train, mae_2_test, mae_2_train]\n",
    "}\n",
    "score_df = pd.DataFrame(\n",
    "    comparing_score,\n",
    "    index=[\n",
    "        'traditional method on test set',\n",
    "        'traditional method on train set',\n",
    "        'IterativeImputer method on test set',\n",
    "        'IterativeImputer method on train set'\n",
    "    ]\n",
    ")\n",
    "score_df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ce9acf48",
   "metadata": {},
   "source": [
    "First, we determine the model performance by the traditional method on the test set and training set. We can see that R-squared on the training set got a better score. It means the model was able to explain all of the variances in the dependent variable better in the training set which is understandable because we use the training set to train the model. So, it's somewhat acceptable if the R-squared score on the training set is higher than on the test set, and also doesn't mean it overfitting.\n",
    "\n",
    "Second, errors on the test set are lower than on the training set meaning that the model performed better on the test set and did not overfit.\n",
    "\n",
    "Third, we determine the model performance between the traditional method and the multivariate imputation method. As we can see that Iterative Imputer got a higher R-squared score and a lower MSE meaning that the model can perform better with this approach, but something to be noticed carefully is MAE.\n",
    "\n",
    "Using multivariate imputer led to a higher MAE compared with the traditional method. My assumption is it was an effect of outliers. According to multivariate imputer, the multivariate imputer algorithm is to define a feature with missing values as a target and other features as input then use a regressor to predict missing values and replace them in the data frame. **Here's the point, we use multiple of outliers as input for imputing missing values, then the filled values would depend on outliers.** However, MSE is something known as sensitive to outliers but got a better score because of the effect of the outliers. shouldn't MSE get higher for imputing more values dependent on outliers? The answer is no. MSE is actually sensitive to outliers, but when outliers increase, MSE will no longer detect them as outliers, instead, it will detect them as another different property of data. The result is a better overall performance would influence over outliers effect and lead to a better MSE value, Unlike MAE which doesn't work that way. MAE literally measures error regardless of emphasizing the distance of error.\n",
    "\n",
    "So, we can't eventually say which one is better because it depends on how data we will use the model on."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "835d1d7b",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "6da0b0cc",
   "metadata": {},
   "source": [
    "Baseline model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ff814cef",
   "metadata": {},
   "source": [
    "Baseline model is a simple model that serves as a starting point for comparison establishing a minimum level of performance that a more sophisticated model should be able to exceed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 560,
   "id": "0e54b050",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[29.02373006, 21.03972772, 25.02717226],\n",
       "       [30.42991064, 21.82822823, 26.12848252],\n",
       "       [29.28315621, 21.30815428, 25.2926183 ],\n",
       "       ...,\n",
       "       [32.58432993, 20.64780252, 26.62097369],\n",
       "       [33.36564866, 21.69189705, 27.53526895],\n",
       "       [33.1480424 , 21.57677892, 27.36857726]])"
      ]
     },
     "execution_count": 560,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d00e5f2b",
   "metadata": {},
   "source": [
    "We inspect the prediction result in order to mock the data to have the same dimension. In this case, we use constant (mean) model as a baseline model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 561,
   "id": "5fe5df0c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[27.04511089, 17.78951053, 22.41163101],\n",
       "       [27.04511089, 17.78951053, 22.41163101],\n",
       "       [27.04511089, 17.78951053, 22.41163101],\n",
       "       ...,\n",
       "       [27.04511089, 17.78951053, 22.41163101],\n",
       "       [27.04511089, 17.78951053, 22.41163101],\n",
       "       [27.04511089, 17.78951053, 22.41163101]])"
      ]
     },
     "execution_count": 561,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "baseline_prediction = np.zeros((y_test.shape[0], 3))\n",
    "baseline_prediction[:, 0] = np.mean(df['MaxTemp'])\n",
    "baseline_prediction[:, 1] = np.mean(df['MinTemp'])\n",
    "baseline_prediction[:, 2] = np.mean(df['MeanTemp'])\n",
    "baseline_prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 562,
   "id": "08f7c3d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline score on test set\n",
      "r2:  -0.2610244341735763 \n",
      " mse:  28.415659594446748 \n",
      " mae:  4.340401475150521\n"
     ]
    }
   ],
   "source": [
    "prediction = baseline_prediction\n",
    "print('Baseline score on test set')\n",
    "r2_baseline, mse_baseline, mae_baseline = make_predict_score(y_test, prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 563,
   "id": "18b52f98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# score_list = [score_r2, score_mse, score_mae]\n",
    "# e.g. causal = 'Baseline Score on test set'\n",
    "def insert_score(score_df, score_list_add, causal):\n",
    "    score_df_add = pd.DataFrame({'R-squared': score_list_add[0], 'MSE': score_list_add[1], 'MAE': score_list_add[2]}, index=[causal])\n",
    "    score_df = pd.concat([score_df, score_df_add], axis=0)\n",
    "    # print(score_df)\n",
    "    return score_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 564,
   "id": "c34b9ff2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>R-squared</th>\n",
       "      <th>MSE</th>\n",
       "      <th>MAE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>traditional method on test set</th>\n",
       "      <td>0.771782</td>\n",
       "      <td>5.191192</td>\n",
       "      <td>1.587086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>traditional method on train set</th>\n",
       "      <td>0.891113</td>\n",
       "      <td>8.979483</td>\n",
       "      <td>1.748859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>IterativeImputer method on test set</th>\n",
       "      <td>0.797888</td>\n",
       "      <td>4.749933</td>\n",
       "      <td>1.657899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>IterativeImputer method on train set</th>\n",
       "      <td>0.934344</td>\n",
       "      <td>5.416664</td>\n",
       "      <td>1.638340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Baseline Score on test set</th>\n",
       "      <td>-0.261024</td>\n",
       "      <td>28.415660</td>\n",
       "      <td>4.340401</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      R-squared        MSE       MAE\n",
       "traditional method on test set         0.771782   5.191192  1.587086\n",
       "traditional method on train set        0.891113   8.979483  1.748859\n",
       "IterativeImputer method on test set    0.797888   4.749933  1.657899\n",
       "IterativeImputer method on train set   0.934344   5.416664  1.638340\n",
       "Baseline Score on test set            -0.261024  28.415660  4.340401"
      ]
     },
     "execution_count": 564,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score_df = insert_score(score_df, [r2_baseline, mse_baseline, mae_baseline], 'Baseline Score on test set')\n",
    "score_df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ca946a38",
   "metadata": {},
   "source": [
    "As we can see, our developed model is quite a lot better than acceptable error from the baseline model. Besides of baseline model, there's a benchmark model which is used to evaluate performace of new models and to compare the performance of new models to the best models that have been developed so far.\n",
    "\n",
    "In this project, we focused on the result from different ML development approaches with the single selected model (RandomForestRegressor). So, there's no further benchmark emphasized in this project."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b1048b89",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "0b5d4319",
   "metadata": {},
   "source": [
    "Normalization (MinMaxScaler, RobustScaler, StandardScaler)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "faef4db5",
   "metadata": {},
   "source": [
    "The first thing before we start."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c54ac925",
   "metadata": {},
   "source": [
    "> *not every dataset require normalization. It is only required only when features have different ranges.*\n",
    "\n",
    "*-- Urvashi Jaitley:* [Link to source](https://medium.com/@urvashilluniya/why-data-normalization-is-necessary-for-machine-learning-models-681b65a05029)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 565,
   "id": "ed24292c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>STA</th>\n",
       "      <th>WindGustSpd</th>\n",
       "      <th>DR</th>\n",
       "      <th>SPD</th>\n",
       "      <th>Precip</th>\n",
       "      <th>MaxTemp</th>\n",
       "      <th>MinTemp</th>\n",
       "      <th>MeanTemp</th>\n",
       "      <th>Snowfall</th>\n",
       "      <th>YR</th>\n",
       "      <th>MO</th>\n",
       "      <th>DA</th>\n",
       "      <th>PRCP</th>\n",
       "      <th>MAX</th>\n",
       "      <th>MIN</th>\n",
       "      <th>MEA</th>\n",
       "      <th>SNF</th>\n",
       "      <th>PGT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>119040.000000</td>\n",
       "      <td>119040.000000</td>\n",
       "      <td>119040.000000</td>\n",
       "      <td>119040.000000</td>\n",
       "      <td>119040.000000</td>\n",
       "      <td>119040.000000</td>\n",
       "      <td>119040.000000</td>\n",
       "      <td>119040.000000</td>\n",
       "      <td>119040.000000</td>\n",
       "      <td>119040.000000</td>\n",
       "      <td>119040.000000</td>\n",
       "      <td>119040.000000</td>\n",
       "      <td>119040.000000</td>\n",
       "      <td>119040.000000</td>\n",
       "      <td>119040.000000</td>\n",
       "      <td>119040.000000</td>\n",
       "      <td>119040.000000</td>\n",
       "      <td>119040.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>29659.435795</td>\n",
       "      <td>37.043283</td>\n",
       "      <td>31.977604</td>\n",
       "      <td>20.001773</td>\n",
       "      <td>3.753917</td>\n",
       "      <td>27.045111</td>\n",
       "      <td>17.789511</td>\n",
       "      <td>22.411631</td>\n",
       "      <td>0.245544</td>\n",
       "      <td>43.805284</td>\n",
       "      <td>6.726016</td>\n",
       "      <td>15.797530</td>\n",
       "      <td>0.150637</td>\n",
       "      <td>81.003745</td>\n",
       "      <td>64.273808</td>\n",
       "      <td>72.644843</td>\n",
       "      <td>0.009667</td>\n",
       "      <td>12.085333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>20953.209402</td>\n",
       "      <td>0.689520</td>\n",
       "      <td>1.070991</td>\n",
       "      <td>0.372311</td>\n",
       "      <td>10.721867</td>\n",
       "      <td>8.717817</td>\n",
       "      <td>8.334572</td>\n",
       "      <td>8.297982</td>\n",
       "      <td>2.613250</td>\n",
       "      <td>1.136718</td>\n",
       "      <td>3.425561</td>\n",
       "      <td>8.794541</td>\n",
       "      <td>0.421693</td>\n",
       "      <td>14.839727</td>\n",
       "      <td>14.453003</td>\n",
       "      <td>14.181324</td>\n",
       "      <td>0.102884</td>\n",
       "      <td>0.380256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>10001.000000</td>\n",
       "      <td>18.520000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-33.333333</td>\n",
       "      <td>-38.333333</td>\n",
       "      <td>-35.555556</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>40.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-28.000000</td>\n",
       "      <td>-37.000000</td>\n",
       "      <td>-32.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>11801.000000</td>\n",
       "      <td>37.040000</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>25.555556</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>20.555556</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>43.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>78.000000</td>\n",
       "      <td>59.000000</td>\n",
       "      <td>69.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>12.085333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>22508.000000</td>\n",
       "      <td>37.040000</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>29.444444</td>\n",
       "      <td>21.111111</td>\n",
       "      <td>25.555556</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>44.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>85.000000</td>\n",
       "      <td>70.000000</td>\n",
       "      <td>78.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>12.085333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>33501.000000</td>\n",
       "      <td>37.040000</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>3.753917</td>\n",
       "      <td>31.666667</td>\n",
       "      <td>23.333333</td>\n",
       "      <td>27.222222</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>45.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>0.150637</td>\n",
       "      <td>89.000000</td>\n",
       "      <td>74.000000</td>\n",
       "      <td>81.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>12.085333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>82506.000000</td>\n",
       "      <td>75.932000</td>\n",
       "      <td>78.000000</td>\n",
       "      <td>41.000000</td>\n",
       "      <td>307.340000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>34.444444</td>\n",
       "      <td>40.000000</td>\n",
       "      <td>86.360000</td>\n",
       "      <td>45.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>31.000000</td>\n",
       "      <td>12.100000</td>\n",
       "      <td>122.000000</td>\n",
       "      <td>94.000000</td>\n",
       "      <td>104.000000</td>\n",
       "      <td>3.400000</td>\n",
       "      <td>23.900000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 STA    WindGustSpd             DR            SPD  \\\n",
       "count  119040.000000  119040.000000  119040.000000  119040.000000   \n",
       "mean    29659.435795      37.043283      31.977604      20.001773   \n",
       "std     20953.209402       0.689520       1.070991       0.372311   \n",
       "min     10001.000000      18.520000       2.000000      10.000000   \n",
       "25%     11801.000000      37.040000      32.000000      20.000000   \n",
       "50%     22508.000000      37.040000      32.000000      20.000000   \n",
       "75%     33501.000000      37.040000      32.000000      20.000000   \n",
       "max     82506.000000      75.932000      78.000000      41.000000   \n",
       "\n",
       "              Precip        MaxTemp        MinTemp       MeanTemp  \\\n",
       "count  119040.000000  119040.000000  119040.000000  119040.000000   \n",
       "mean        3.753917      27.045111      17.789511      22.411631   \n",
       "std        10.721867       8.717817       8.334572       8.297982   \n",
       "min         0.000000     -33.333333     -38.333333     -35.555556   \n",
       "25%         0.000000      25.555556      15.000000      20.555556   \n",
       "50%         0.000000      29.444444      21.111111      25.555556   \n",
       "75%         3.753917      31.666667      23.333333      27.222222   \n",
       "max       307.340000      50.000000      34.444444      40.000000   \n",
       "\n",
       "            Snowfall             YR             MO             DA  \\\n",
       "count  119040.000000  119040.000000  119040.000000  119040.000000   \n",
       "mean        0.245544      43.805284       6.726016      15.797530   \n",
       "std         2.613250       1.136718       3.425561       8.794541   \n",
       "min         0.000000      40.000000       1.000000       1.000000   \n",
       "25%         0.000000      43.000000       4.000000       8.000000   \n",
       "50%         0.000000      44.000000       7.000000      16.000000   \n",
       "75%         0.000000      45.000000      10.000000      23.000000   \n",
       "max        86.360000      45.000000      12.000000      31.000000   \n",
       "\n",
       "                PRCP            MAX            MIN            MEA  \\\n",
       "count  119040.000000  119040.000000  119040.000000  119040.000000   \n",
       "mean        0.150637      81.003745      64.273808      72.644843   \n",
       "std         0.421693      14.839727      14.453003      14.181324   \n",
       "min         0.000000     -28.000000     -37.000000     -32.000000   \n",
       "25%         0.000000      78.000000      59.000000      69.000000   \n",
       "50%         0.000000      85.000000      70.000000      78.000000   \n",
       "75%         0.150637      89.000000      74.000000      81.000000   \n",
       "max        12.100000     122.000000      94.000000     104.000000   \n",
       "\n",
       "                 SNF            PGT  \n",
       "count  119040.000000  119040.000000  \n",
       "mean        0.009667      12.085333  \n",
       "std         0.102884       0.380256  \n",
       "min         0.000000       0.000000  \n",
       "25%         0.000000      12.085333  \n",
       "50%         0.000000      12.085333  \n",
       "75%         0.000000      12.085333  \n",
       "max         3.400000      23.900000  "
      ]
     },
     "execution_count": 565,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "4b1308bb",
   "metadata": {},
   "source": [
    "We're still not sure if normalization would give a better performance for the model. It's worth a try for a learning purpose."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "4fae7a85",
   "metadata": {},
   "source": [
    "first, we use the dataframe with tradition fillng (df)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 566,
   "id": "8d9b94a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scale_split(scaler, dataframe):\n",
    "    \n",
    "    # train test split data\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = split_data(dataframe)\n",
    "\n",
    "    # normalize training data\n",
    "    \n",
    "    scaler_fitted = scaler.fit(X_train)\n",
    "    X_train_norm = scaler_fitted.transform(X_train)\n",
    "\n",
    "    # converting array to dataframe\n",
    "\n",
    "    X_train_norm_df = pd.DataFrame(X_train_norm, index=X_train.index, columns=X_train.columns)\n",
    "    # X_train.update(X_train_norm_df)\n",
    "\n",
    "    # normalize test data by using mean and sd of training set\n",
    "\n",
    "    X_test_norm = scaler_fitted.transform(X_test)\n",
    "    X_test_norm_df = pd.DataFrame(X_test_norm, index=X_test.index, columns=X_test.columns)\n",
    "    # X_train.update(X_train_norm_df)\n",
    "\n",
    "    return X_train_norm_df, X_test_norm_df, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 567,
   "id": "462366d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "StandardScaler score on test set\n",
      "r2:  0.7717823464712087 \n",
      " mse:  5.191191853921098 \n",
      " mae:  1.5870862904809122\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>R-squared</th>\n",
       "      <th>MSE</th>\n",
       "      <th>MAE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>traditional method on test set</th>\n",
       "      <td>0.771782</td>\n",
       "      <td>5.191192</td>\n",
       "      <td>1.587086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>traditional method on train set</th>\n",
       "      <td>0.891113</td>\n",
       "      <td>8.979483</td>\n",
       "      <td>1.748859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>IterativeImputer method on test set</th>\n",
       "      <td>0.797888</td>\n",
       "      <td>4.749933</td>\n",
       "      <td>1.657899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>IterativeImputer method on train set</th>\n",
       "      <td>0.934344</td>\n",
       "      <td>5.416664</td>\n",
       "      <td>1.638340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Baseline Score on test set</th>\n",
       "      <td>-0.261024</td>\n",
       "      <td>28.415660</td>\n",
       "      <td>4.340401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Score using StandardScaler with traditional method to filling missing value</th>\n",
       "      <td>0.771782</td>\n",
       "      <td>5.191192</td>\n",
       "      <td>1.587086</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    R-squared        MSE  \\\n",
       "traditional method on test set                       0.771782   5.191192   \n",
       "traditional method on train set                      0.891113   8.979483   \n",
       "IterativeImputer method on test set                  0.797888   4.749933   \n",
       "IterativeImputer method on train set                 0.934344   5.416664   \n",
       "Baseline Score on test set                          -0.261024  28.415660   \n",
       "Score using StandardScaler with traditional met...   0.771782   5.191192   \n",
       "\n",
       "                                                         MAE  \n",
       "traditional method on test set                      1.587086  \n",
       "traditional method on train set                     1.748859  \n",
       "IterativeImputer method on test set                 1.657899  \n",
       "IterativeImputer method on train set                1.638340  \n",
       "Baseline Score on test set                          4.340401  \n",
       "Score using StandardScaler with traditional met...  1.587086  "
      ]
     },
     "execution_count": 567,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# normalize by selected scaler\n",
    "\n",
    "X_train_norm_df, X_test_norm_df, y_train, y_test = scale_split(StandardScaler(), df)\n",
    "\n",
    "# train model with scaled data\n",
    "\n",
    "model = RandomForestRegressor(n_estimators=100, criterion='squared_error', max_depth=4, max_features='sqrt', bootstrap=True, random_state=1)\n",
    "model.fit(X_train_norm_df, y_train)\n",
    "\n",
    "# evaluate performance\n",
    "\n",
    "prediction = model.predict(X_test_norm_df)\n",
    "print('StandardScaler score on test set')\n",
    "r2_norm1, mse_norm1, mae_norm1 = make_predict_score(y_test, prediction)\n",
    "\n",
    "# Insert the score for comparison\n",
    "\n",
    "score_df = insert_score(score_df, [r2_norm1, mse_norm1, mae_norm1], 'Score using StandardScaler with traditional method to filling missing value')\n",
    "score_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 568,
   "id": "74250019",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RobustScaler score on test set\n",
      "r2:  0.7717823464712087 \n",
      " mse:  5.191191853921098 \n",
      " mae:  1.5870862904809122\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>R-squared</th>\n",
       "      <th>MSE</th>\n",
       "      <th>MAE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>traditional method on test set</th>\n",
       "      <td>0.771782</td>\n",
       "      <td>5.191192</td>\n",
       "      <td>1.587086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>traditional method on train set</th>\n",
       "      <td>0.891113</td>\n",
       "      <td>8.979483</td>\n",
       "      <td>1.748859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>IterativeImputer method on test set</th>\n",
       "      <td>0.797888</td>\n",
       "      <td>4.749933</td>\n",
       "      <td>1.657899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>IterativeImputer method on train set</th>\n",
       "      <td>0.934344</td>\n",
       "      <td>5.416664</td>\n",
       "      <td>1.638340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Baseline Score on test set</th>\n",
       "      <td>-0.261024</td>\n",
       "      <td>28.415660</td>\n",
       "      <td>4.340401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Score using StandardScaler with traditional method to filling missing value</th>\n",
       "      <td>0.771782</td>\n",
       "      <td>5.191192</td>\n",
       "      <td>1.587086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Score using RobustScaler with traditional method to filling missing value</th>\n",
       "      <td>0.771782</td>\n",
       "      <td>5.191192</td>\n",
       "      <td>1.587086</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    R-squared        MSE  \\\n",
       "traditional method on test set                       0.771782   5.191192   \n",
       "traditional method on train set                      0.891113   8.979483   \n",
       "IterativeImputer method on test set                  0.797888   4.749933   \n",
       "IterativeImputer method on train set                 0.934344   5.416664   \n",
       "Baseline Score on test set                          -0.261024  28.415660   \n",
       "Score using StandardScaler with traditional met...   0.771782   5.191192   \n",
       "Score using RobustScaler with traditional metho...   0.771782   5.191192   \n",
       "\n",
       "                                                         MAE  \n",
       "traditional method on test set                      1.587086  \n",
       "traditional method on train set                     1.748859  \n",
       "IterativeImputer method on test set                 1.657899  \n",
       "IterativeImputer method on train set                1.638340  \n",
       "Baseline Score on test set                          4.340401  \n",
       "Score using StandardScaler with traditional met...  1.587086  \n",
       "Score using RobustScaler with traditional metho...  1.587086  "
      ]
     },
     "execution_count": 568,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# normalize by selected scaler\n",
    "\n",
    "X_train_norm_df, X_test_norm_df, y_train, y_test = scale_split(RobustScaler(), df)\n",
    "\n",
    "# train model with scaled data\n",
    "\n",
    "model = RandomForestRegressor(n_estimators=100, criterion='squared_error', max_depth=4, max_features='sqrt', bootstrap=True, random_state=1)\n",
    "model.fit(X_train_norm_df, y_train)\n",
    "\n",
    "# evaluate performance\n",
    "\n",
    "prediction = model.predict(X_test_norm_df)\n",
    "print('RobustScaler score on test set')\n",
    "r2_norm2, mse_norm2, mae_norm2 = make_predict_score(y_test, prediction)\n",
    "\n",
    "# Insert the score for comparison\n",
    "\n",
    "score_df = insert_score(score_df, [r2_norm2, mse_norm2, mae_norm2], 'Score using RobustScaler with traditional method to filling missing value')\n",
    "score_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 569,
   "id": "fc9917c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MinMaxScaler score on test set\n",
      "r2:  0.7717823464712087 \n",
      " mse:  5.191191853921098 \n",
      " mae:  1.5870862904809122\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>R-squared</th>\n",
       "      <th>MSE</th>\n",
       "      <th>MAE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>traditional method on test set</th>\n",
       "      <td>0.771782</td>\n",
       "      <td>5.191192</td>\n",
       "      <td>1.587086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>traditional method on train set</th>\n",
       "      <td>0.891113</td>\n",
       "      <td>8.979483</td>\n",
       "      <td>1.748859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>IterativeImputer method on test set</th>\n",
       "      <td>0.797888</td>\n",
       "      <td>4.749933</td>\n",
       "      <td>1.657899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>IterativeImputer method on train set</th>\n",
       "      <td>0.934344</td>\n",
       "      <td>5.416664</td>\n",
       "      <td>1.638340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Baseline Score on test set</th>\n",
       "      <td>-0.261024</td>\n",
       "      <td>28.415660</td>\n",
       "      <td>4.340401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Score using StandardScaler with traditional method to filling missing value</th>\n",
       "      <td>0.771782</td>\n",
       "      <td>5.191192</td>\n",
       "      <td>1.587086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Score using RobustScaler with traditional method to filling missing value</th>\n",
       "      <td>0.771782</td>\n",
       "      <td>5.191192</td>\n",
       "      <td>1.587086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Score using MinMaxScaler with traditional method to fill missing value</th>\n",
       "      <td>0.771782</td>\n",
       "      <td>5.191192</td>\n",
       "      <td>1.587086</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    R-squared        MSE  \\\n",
       "traditional method on test set                       0.771782   5.191192   \n",
       "traditional method on train set                      0.891113   8.979483   \n",
       "IterativeImputer method on test set                  0.797888   4.749933   \n",
       "IterativeImputer method on train set                 0.934344   5.416664   \n",
       "Baseline Score on test set                          -0.261024  28.415660   \n",
       "Score using StandardScaler with traditional met...   0.771782   5.191192   \n",
       "Score using RobustScaler with traditional metho...   0.771782   5.191192   \n",
       "Score using MinMaxScaler with traditional metho...   0.771782   5.191192   \n",
       "\n",
       "                                                         MAE  \n",
       "traditional method on test set                      1.587086  \n",
       "traditional method on train set                     1.748859  \n",
       "IterativeImputer method on test set                 1.657899  \n",
       "IterativeImputer method on train set                1.638340  \n",
       "Baseline Score on test set                          4.340401  \n",
       "Score using StandardScaler with traditional met...  1.587086  \n",
       "Score using RobustScaler with traditional metho...  1.587086  \n",
       "Score using MinMaxScaler with traditional metho...  1.587086  "
      ]
     },
     "execution_count": 569,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# normalize by selected scaler\n",
    "\n",
    "X_train_norm_df, X_test_norm_df, y_train, y_test = scale_split(MinMaxScaler(), df)\n",
    "\n",
    "# train model with scaled data\n",
    "\n",
    "model = RandomForestRegressor(n_estimators=100, criterion='squared_error', max_depth=4, max_features='sqrt', bootstrap=True, random_state=1)\n",
    "model.fit(X_train_norm_df, y_train)\n",
    "\n",
    "# evaluate performance\n",
    "\n",
    "prediction = model.predict(X_test_norm_df)\n",
    "print('MinMaxScaler score on test set')\n",
    "r2_norm3, mse_norm3, mae_norm3 = make_predict_score(y_test, prediction)\n",
    "\n",
    "# Insert the score for comparison\n",
    "\n",
    "score_df = insert_score(score_df, [r2_norm3, mse_norm3, mae_norm3], 'Score using MinMaxScaler with traditional method to fill missing value')\n",
    "score_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 570,
   "id": "0b348fe8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "StandardScaler score on test set\n",
      "r2:  0.409189503520974 \n",
      " mse:  13.305415471310207 \n",
      " mae:  2.9395120370550116\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>R-squared</th>\n",
       "      <th>MSE</th>\n",
       "      <th>MAE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>traditional method on test set</th>\n",
       "      <td>0.771782</td>\n",
       "      <td>5.191192</td>\n",
       "      <td>1.587086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>traditional method on train set</th>\n",
       "      <td>0.891113</td>\n",
       "      <td>8.979483</td>\n",
       "      <td>1.748859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>IterativeImputer method on test set</th>\n",
       "      <td>0.797888</td>\n",
       "      <td>4.749933</td>\n",
       "      <td>1.657899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>IterativeImputer method on train set</th>\n",
       "      <td>0.934344</td>\n",
       "      <td>5.416664</td>\n",
       "      <td>1.638340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Baseline Score on test set</th>\n",
       "      <td>-0.261024</td>\n",
       "      <td>28.415660</td>\n",
       "      <td>4.340401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Score using StandardScaler with traditional method to filling missing value</th>\n",
       "      <td>0.771782</td>\n",
       "      <td>5.191192</td>\n",
       "      <td>1.587086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Score using RobustScaler with traditional method to filling missing value</th>\n",
       "      <td>0.771782</td>\n",
       "      <td>5.191192</td>\n",
       "      <td>1.587086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Score using MinMaxScaler with traditional method to fill missing value</th>\n",
       "      <td>0.771782</td>\n",
       "      <td>5.191192</td>\n",
       "      <td>1.587086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Score using StandardScaler with IterativeImputer to fill missing value</th>\n",
       "      <td>0.409190</td>\n",
       "      <td>13.305415</td>\n",
       "      <td>2.939512</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    R-squared        MSE  \\\n",
       "traditional method on test set                       0.771782   5.191192   \n",
       "traditional method on train set                      0.891113   8.979483   \n",
       "IterativeImputer method on test set                  0.797888   4.749933   \n",
       "IterativeImputer method on train set                 0.934344   5.416664   \n",
       "Baseline Score on test set                          -0.261024  28.415660   \n",
       "Score using StandardScaler with traditional met...   0.771782   5.191192   \n",
       "Score using RobustScaler with traditional metho...   0.771782   5.191192   \n",
       "Score using MinMaxScaler with traditional metho...   0.771782   5.191192   \n",
       "Score using StandardScaler with IterativeImpute...   0.409190  13.305415   \n",
       "\n",
       "                                                         MAE  \n",
       "traditional method on test set                      1.587086  \n",
       "traditional method on train set                     1.748859  \n",
       "IterativeImputer method on test set                 1.657899  \n",
       "IterativeImputer method on train set                1.638340  \n",
       "Baseline Score on test set                          4.340401  \n",
       "Score using StandardScaler with traditional met...  1.587086  \n",
       "Score using RobustScaler with traditional metho...  1.587086  \n",
       "Score using MinMaxScaler with traditional metho...  1.587086  \n",
       "Score using StandardScaler with IterativeImpute...  2.939512  "
      ]
     },
     "execution_count": 570,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# normalize by selected scaler\n",
    "\n",
    "X_train_norm_df, X_test_norm_df, y_train, y_test = scale_split(StandardScaler(), df_temp)\n",
    "\n",
    "# train model with scaled data\n",
    "\n",
    "model = RandomForestRegressor(n_estimators=100, criterion='squared_error', max_depth=4, max_features='sqrt', bootstrap=True, random_state=1)\n",
    "model.fit(X_train_norm_df, y_train)\n",
    "\n",
    "# evaluate performance\n",
    "\n",
    "prediction = model.predict(X_test_norm_df)\n",
    "print('StandardScaler score on test set')\n",
    "r2_norm4, mse_norm4, mae_norm4 = make_predict_score(y_test, prediction)\n",
    "\n",
    "# Insert the score for comparison\n",
    "\n",
    "score_df = insert_score(score_df, [r2_norm4, mse_norm4, mae_norm4], 'Score using StandardScaler with IterativeImputer to fill missing value')\n",
    "score_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 571,
   "id": "0b348fe8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RobustScaler score on test set\n",
      "r2:  0.7981313248475953 \n",
      " mse:  4.744384270833911 \n",
      " mae:  1.6573353227442225\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>R-squared</th>\n",
       "      <th>MSE</th>\n",
       "      <th>MAE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>traditional method on test set</th>\n",
       "      <td>0.771782</td>\n",
       "      <td>5.191192</td>\n",
       "      <td>1.587086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>traditional method on train set</th>\n",
       "      <td>0.891113</td>\n",
       "      <td>8.979483</td>\n",
       "      <td>1.748859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>IterativeImputer method on test set</th>\n",
       "      <td>0.797888</td>\n",
       "      <td>4.749933</td>\n",
       "      <td>1.657899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>IterativeImputer method on train set</th>\n",
       "      <td>0.934344</td>\n",
       "      <td>5.416664</td>\n",
       "      <td>1.638340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Baseline Score on test set</th>\n",
       "      <td>-0.261024</td>\n",
       "      <td>28.415660</td>\n",
       "      <td>4.340401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Score using StandardScaler with traditional method to filling missing value</th>\n",
       "      <td>0.771782</td>\n",
       "      <td>5.191192</td>\n",
       "      <td>1.587086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Score using RobustScaler with traditional method to filling missing value</th>\n",
       "      <td>0.771782</td>\n",
       "      <td>5.191192</td>\n",
       "      <td>1.587086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Score using MinMaxScaler with traditional method to fill missing value</th>\n",
       "      <td>0.771782</td>\n",
       "      <td>5.191192</td>\n",
       "      <td>1.587086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Score using StandardScaler with IterativeImputer to fill missing value</th>\n",
       "      <td>0.409190</td>\n",
       "      <td>13.305415</td>\n",
       "      <td>2.939512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Score using RobustScaler with IterativeImputer to fill missing value</th>\n",
       "      <td>0.798131</td>\n",
       "      <td>4.744384</td>\n",
       "      <td>1.657335</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    R-squared        MSE  \\\n",
       "traditional method on test set                       0.771782   5.191192   \n",
       "traditional method on train set                      0.891113   8.979483   \n",
       "IterativeImputer method on test set                  0.797888   4.749933   \n",
       "IterativeImputer method on train set                 0.934344   5.416664   \n",
       "Baseline Score on test set                          -0.261024  28.415660   \n",
       "Score using StandardScaler with traditional met...   0.771782   5.191192   \n",
       "Score using RobustScaler with traditional metho...   0.771782   5.191192   \n",
       "Score using MinMaxScaler with traditional metho...   0.771782   5.191192   \n",
       "Score using StandardScaler with IterativeImpute...   0.409190  13.305415   \n",
       "Score using RobustScaler with IterativeImputer ...   0.798131   4.744384   \n",
       "\n",
       "                                                         MAE  \n",
       "traditional method on test set                      1.587086  \n",
       "traditional method on train set                     1.748859  \n",
       "IterativeImputer method on test set                 1.657899  \n",
       "IterativeImputer method on train set                1.638340  \n",
       "Baseline Score on test set                          4.340401  \n",
       "Score using StandardScaler with traditional met...  1.587086  \n",
       "Score using RobustScaler with traditional metho...  1.587086  \n",
       "Score using MinMaxScaler with traditional metho...  1.587086  \n",
       "Score using StandardScaler with IterativeImpute...  2.939512  \n",
       "Score using RobustScaler with IterativeImputer ...  1.657335  "
      ]
     },
     "execution_count": 571,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# normalize by selected scaler\n",
    "\n",
    "X_train_norm_df, X_test_norm_df, y_train, y_test = scale_split(RobustScaler(), df_temp)\n",
    "\n",
    "# train model with scaled data\n",
    "\n",
    "model = RandomForestRegressor(n_estimators=100, criterion='squared_error', max_depth=4, max_features='sqrt', bootstrap=True, random_state=1)\n",
    "model.fit(X_train_norm_df, y_train)\n",
    "\n",
    "# evaluate performance\n",
    "\n",
    "prediction = model.predict(X_test_norm_df)\n",
    "print('RobustScaler score on test set')\n",
    "r2_norm5, mse_norm5, mae_norm5 = make_predict_score(y_test, prediction)\n",
    "\n",
    "# Insert the score for comparison\n",
    "\n",
    "score_df = insert_score(score_df, [r2_norm5, mse_norm5, mae_norm5], 'Score using RobustScaler with IterativeImputer to fill missing value')\n",
    "score_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 572,
   "id": "0b348fe8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MinMaxScaler score on test set\n",
      "r2:  0.400965145738901 \n",
      " mse:  13.487000303116337 \n",
      " mae:  2.960069057619656\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>R-squared</th>\n",
       "      <th>MSE</th>\n",
       "      <th>MAE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>traditional method on test set</th>\n",
       "      <td>0.771782</td>\n",
       "      <td>5.191192</td>\n",
       "      <td>1.587086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>traditional method on train set</th>\n",
       "      <td>0.891113</td>\n",
       "      <td>8.979483</td>\n",
       "      <td>1.748859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>IterativeImputer method on test set</th>\n",
       "      <td>0.797888</td>\n",
       "      <td>4.749933</td>\n",
       "      <td>1.657899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>IterativeImputer method on train set</th>\n",
       "      <td>0.934344</td>\n",
       "      <td>5.416664</td>\n",
       "      <td>1.638340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Baseline Score on test set</th>\n",
       "      <td>-0.261024</td>\n",
       "      <td>28.415660</td>\n",
       "      <td>4.340401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Score using StandardScaler with traditional method to filling missing value</th>\n",
       "      <td>0.771782</td>\n",
       "      <td>5.191192</td>\n",
       "      <td>1.587086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Score using RobustScaler with traditional method to filling missing value</th>\n",
       "      <td>0.771782</td>\n",
       "      <td>5.191192</td>\n",
       "      <td>1.587086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Score using MinMaxScaler with traditional method to fill missing value</th>\n",
       "      <td>0.771782</td>\n",
       "      <td>5.191192</td>\n",
       "      <td>1.587086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Score using StandardScaler with IterativeImputer to fill missing value</th>\n",
       "      <td>0.409190</td>\n",
       "      <td>13.305415</td>\n",
       "      <td>2.939512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Score using RobustScaler with IterativeImputer to fill missing value</th>\n",
       "      <td>0.798131</td>\n",
       "      <td>4.744384</td>\n",
       "      <td>1.657335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Score using MinMaxScaler with IterativeImputer to fill missing value</th>\n",
       "      <td>0.400965</td>\n",
       "      <td>13.487000</td>\n",
       "      <td>2.960069</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    R-squared        MSE  \\\n",
       "traditional method on test set                       0.771782   5.191192   \n",
       "traditional method on train set                      0.891113   8.979483   \n",
       "IterativeImputer method on test set                  0.797888   4.749933   \n",
       "IterativeImputer method on train set                 0.934344   5.416664   \n",
       "Baseline Score on test set                          -0.261024  28.415660   \n",
       "Score using StandardScaler with traditional met...   0.771782   5.191192   \n",
       "Score using RobustScaler with traditional metho...   0.771782   5.191192   \n",
       "Score using MinMaxScaler with traditional metho...   0.771782   5.191192   \n",
       "Score using StandardScaler with IterativeImpute...   0.409190  13.305415   \n",
       "Score using RobustScaler with IterativeImputer ...   0.798131   4.744384   \n",
       "Score using MinMaxScaler with IterativeImputer ...   0.400965  13.487000   \n",
       "\n",
       "                                                         MAE  \n",
       "traditional method on test set                      1.587086  \n",
       "traditional method on train set                     1.748859  \n",
       "IterativeImputer method on test set                 1.657899  \n",
       "IterativeImputer method on train set                1.638340  \n",
       "Baseline Score on test set                          4.340401  \n",
       "Score using StandardScaler with traditional met...  1.587086  \n",
       "Score using RobustScaler with traditional metho...  1.587086  \n",
       "Score using MinMaxScaler with traditional metho...  1.587086  \n",
       "Score using StandardScaler with IterativeImpute...  2.939512  \n",
       "Score using RobustScaler with IterativeImputer ...  1.657335  \n",
       "Score using MinMaxScaler with IterativeImputer ...  2.960069  "
      ]
     },
     "execution_count": 572,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# normalize by selected scaler\n",
    "\n",
    "X_train_norm_df, X_test_norm_df, y_train, y_test = scale_split(MinMaxScaler(), df_temp)\n",
    "\n",
    "# train model with scaled data\n",
    "\n",
    "model = RandomForestRegressor(n_estimators=100, criterion='squared_error', max_depth=4, max_features='sqrt', bootstrap=True, random_state=1)\n",
    "model.fit(X_train_norm_df, y_train)\n",
    "\n",
    "# evaluate performance\n",
    "\n",
    "prediction = model.predict(X_test_norm_df)\n",
    "print('MinMaxScaler score on test set')\n",
    "r2_norm6, mse_norm6, mae_norm6 = make_predict_score(y_test, prediction)\n",
    "\n",
    "# Insert the score for comparison\n",
    "\n",
    "score_df = insert_score(score_df, [r2_norm6, mse_norm6, mae_norm6], 'Score using MinMaxScaler with IterativeImputer to fill missing value')\n",
    "score_df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "03a457f0",
   "metadata": {},
   "source": [
    "There's a lot interpretation to discuss here, but I will leave it to readers. My choice is using RobustScaler with Multivariate Imputation which seemed to be the best performance so far."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e9829703",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "066e9710",
   "metadata": {},
   "source": [
    "Further in this project will expand to using other variants of IterativeImputer (RandomRegressor), time series cross validator (TimeSeriesSplit), and optimizing model tuning (which is skipped and not done properly in previous part of the project)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "a9cff5a362bc38ef45d817ae74b1af54d6a076e3d773891282bce078b815ba34"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
